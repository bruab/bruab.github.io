---
layout: post
title: "The worst outcome in A/B testing"
date: "2019-08-06"
---

... is "results were inconclusive; further testing necessary."

You built and QA'd the test. Spent the time and money.

Ran and monitored the test. Watched the metrics and kept everyone up to date.

Concluded and analyzed the test. Puzzled over the results.

And nothing has changed.

You don't know whether this page (or element) is _worth_ testing on, so you have to test more. You don't know if you tested the wrong kind of change, or if you just need to test a _bigger_ change ... or if you made multiple changes that somehow cancelled each other out ðŸ¤”

You definitely don't have a more valuable website than when you started.

Contrast this outcome with "results were inconclusive; _no_ further testing necessary."

You're still stuck with the same old conversion rate, but there's a good chance your _next_ test will change that. Because you know where _not_ to test.

To get the latter outcome:

- **Test big changes.** Certain audiences are sensitive to subtle changes in certain elements, but unless you _know_ that's your situation, you're better off being a bit more aggressive
- **Test more variations.** A single inconclusive variation is pretty meaningless; _six_ inconclusive variations clearly communicate "Nothing to see here"
