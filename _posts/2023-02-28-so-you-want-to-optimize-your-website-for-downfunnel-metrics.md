---
layout: post
title: "So you want to optimize your website for downfunnel metrics"
date: 2023-02-28
tags: []
---

You've gotten pretty good at running A/B tests on your B2B lead gen website, optimizing for engagement or form fills but ... form fills aren't money.

I mean, _some_ form fills become sales-qualified leads (SQLs), and opportunities ("opps"), and end up becoming closed-won deals. But most of them don't. 

So maybe it feels like a waste of time to optimize a metric so far removed from revenue. Why not optimize for SQLs, or opps, or even ... deals?

Fair question. Here's my advice.

## 1. Don't.

You're driving a steady, cumulative increase in form fills. Have they corresponded to a steady, cumulative increase in deals and revenue?

If so, just keep doing what you're doing.

The HUGE upside of this is that your measurement strategy remains simple (everything happens directly on the website) and you've got plenty of data, so you won't be tempted to compromise statistical rigor.

Have faith, stay the course. You're doing great.

But if you're _not_ seeing a link between form fills and deals, or if you're simply determined to choose a more challenging (and admittedly more relevant) success metric ...


## 2. Focus on revenue per visitor (RPV)

Go all the way to the end of the funnel.

That's what you care about, right? So don't waste time toying around with made-up preliminary lead qualification stages like SQLs or mega-SQLs or Opps. It's true that "form fills aren't money" but ... neither are Opps.

As a reality check, run an [RPV significance calculation](https://www.blastanalytics.com/rpv-calculator) on one of your most recent experiments, and an [A/A test](/the-mighty-a-a-test/).

You'll need to massage the data a bit to get it into the right format. And of course you'll need to know which closed-won deals saw which experience in the experiment. (Nobody said this would be easy.)

If you find that you have sufficient data to measure experiments based on revenue per visitor, you're done.

This will inevitably slow down the velocity with which you launch, conclude, and act on test results, but the impact on the bottom line will be unmistakeable.

If, however, you find that you're not closing enough deals to support this type of analysis ...

## 3. Move up the funnel until you find a metric you can reasonably optimize

No more weird RPV calculators—we're back in the realm of "how many visitors? how many conversions?"

Can you optimize for closed-won deals? Do that. If not, try Opps. If that's a no go, try SQLs.

The goal is to choose a metric that's as close to revenue as possible. This is extremely important, because _second-guessing the true impact of your winning experiments is what started you down this path._

If you start optimizing for downfunnel metrics—at considerable expense in terms of analytics complexity and test duration—only to find you _still_ doubt your results, you have lost.

(You may, at this point, wish to refer back to suggestion #1.)

Whatever you end up measuring, just one more note.

## 4. Decide in advance which tests require downfunnel analysis

Don't fall into the habit of "just peeking" at the numbers for every test. Fear the [multiple comparisons problem](/how-the-multiple-comparisons-problem-will-ruin-your-life/). Allow yourself to focus on engagement and form fills when there's no plausible reason to suspect a winning variant might somehow wreak havoc with the sales pipeline.

In other words, if you're thinking about optimizing for downfunnel metrics, either (a) don't, or (b) usually don't.
